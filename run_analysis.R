## Coursera
## Getting and Cleaning Data Course Project

# Download and unzip raw data function
downloadsource <- function(fileurl, destfile, unzippeddirname) {
        ## local variables
        datafolder <- "./data"
        destfile <- paste0(datafolder, "/", destfile)
        
        ## create data directory if not exists
        if(!file.exists(datafolder)){dir.create(datafolder)}
        
        ## download a zip file containing raw data and save it to the data directory from working directory
        ## method="wininet" for windows system
        if(!file.exists(destfile)) {
                download.file(fileurl, destfile = destfile, method="wininet")
        }
        
        # unzip the directory if not exists
        if (!file.exists(unzippeddirname)) { 
                unzip(destfile)
        }
        
        ## print when the file was download:
        print(paste("zip file downloaded on:", 
                    format(Sys.time(), "%b %d, %Y %X"),
                    "from:", fileurl))
}

writecsvfile <- function(dataset, destfile, ...) {
        
        ## remove file if was generated by previous run
        if(file.exists(destfile)){file.remove(destfile)}
        
        ## create file
        write.csv(dataset, destfile, ...)
        
        ## no print
        invisible()
}

run_analysis <- function (){
        
        ## Set working directory
        if(!file.exists("~/course_3_DataCleaning_ClassProject")){dir.create("~/course_3_DataCleaning_ClassProject")}
        setwd("~/course_3_DataCleaning_ClassProject/")
        
        ## Required libraries
        ## install.packages("dplyr")
        print("Required libraries: dplyr, tidyr")
        library(dplyr)
        library(tidyr)      
                
        ## The data for the project and local variables
        fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
        destfile <- "rawdata.zip"
        unzippeddirname <- "UCI HAR Dataset"
        
        ## download and unzip directory
        downloadsource(fileurl, destfile, unzippeddirname)
        
        print("Step 1 -> Reads and merges the training and the test sets to create one data set.")
        # read data from trining files and add support information as column
        trainingset <- read.table("./UCI HAR Dataset/train/X_train.txt", stringsAsFactors = FALSE, header = FALSE)
        traininglabel <- read.table("./UCI HAR Dataset/train/y_train.txt", stringsAsFactors = FALSE, header = FALSE)
        trainingsubject <- read.table("./UCI HAR Dataset/train/subject_train.txt", stringsAsFactors = FALSE, header = FALSE)
        trainingset <- trainingset %>% mutate(activityid = traininglabel[,1], subject = trainingsubject[,1])
        
        # read data from testing files and add support information as column
        testingset <- read.table("./UCI HAR Dataset/test/X_test.txt", stringsAsFactors = FALSE, header = FALSE)
        testinglabel <- read.table("./UCI HAR Dataset/test/y_test.txt", stringsAsFactors = FALSE, header = FALSE)
        testingsubject <- read.table("./UCI HAR Dataset/test/subject_test.txt", stringsAsFactors = FALSE, header = FALSE)
        testingset <- testingset %>% mutate(activityid = testinglabel[,1], subject = testingsubject[,1])
        
        # remove variables from memory
        rm(traininglabel) 
        rm(trainingsubject)
        rm(testinglabel)
        rm(testingsubject)
        
        # merge data in one dataset
        completedataset <- rbind(trainingset, testingset)
        
        print("Step 2 -> Extracts only the measurements on the mean and standard deviation for each measurement.")
        # -> read additional data to identify activities lables and features names
        activitylabels <- read.table("./UCI HAR Dataset/activity_labels.txt", stringsAsFactors = FALSE, header = FALSE, col.names = c("activityid", "activity"))
        features <- read.table("./UCI HAR Dataset/features.txt", stringsAsFactors = FALSE, header = FALSE, col.names = c("featureid", "feature"))
        
        # -> identify required features 
        requiredfeatures <- grep("mean\\(\\)|std\\(\\)", features$feature)
        # -> identify logical coulmns
        logiccolumns <- grep("activityid|subject",names(completedataset))
        # -> combined columns indexes; first ones should be the logic key columns
        requiredcolumns <- c(logiccolumns, requiredfeatures)
       
        # extract only required columns
        tidydataset <- completedataset[,requiredcolumns]
        # remove completedataset variable from memory
        rm(completedataset)
        
        print("Step 3 -> Uses descriptive activity names to name the activities in the data set")
        # -> Add activity name to the tidydataset
        tidydataset <- merge(activitylabels, tidydataset, all = TRUE)
        
        # remove activityid from columns
        tidydataset <- select(tidydataset, -activityid)
        
        print("Step 4 -> Appropriately labels the data set with descriptive variable names")
        # -> replace special characters from variable name & set them to lower case; variable 1 and variable 2 are logical and don't need to be updated
        # -> test if at least one feature was found at step 2
        if(length(features$feature[requiredfeatures]) > 0){
                lastfeatureindex <- length(features$feature[requiredfeatures]) + 2
                names(tidydataset)[3:lastfeatureindex] <- gsub("-|\\(\\)", "", tolower(features$feature[requiredfeatures])) 
        }
        print("Write first tidy dataset to firsttidydataset.csv file to the working directory")
        writecsvfile (tidydataset, "firsttidydataset.csv", row.names=FALSE)
        
        print("Step 5 -> From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject ")
        # -> test if at least one feature was found at step 2
        if(length(features$feature[requiredfeatures]) > 0){
                secondtidydataset <- tbl_df(tidydataset) %>% 
                                group_by(activity, subject) %>%
                                        summarise_all(mean, na.rm=TRUE)
        }
        print("Write second tidy dataset to secondtidydataset.csv file to the working directory")
        writecsvfile (secondtidydataset, "secondtidydataset.csv", row.names=FALSE)
        
        print("Write tidy dataset as tidy.txt file to the working directory as per submission request")
        ## remove file if was generated by previous run
        if(file.exists("tidy.txt")){file.remove("tidy.txt")}
        write.table(secondtidydataset, "tidy.txt", row.name=FALSE, quote = FALSE) 
        
        print(paste("Analysis done! Tidy files can be found here:", getwd()))
        
        
}

## To run the analysis:
## source("run_analysis.R") #if the file exist in your working directory
## run_analysis()



